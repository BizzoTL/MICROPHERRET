{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mette insieme i modelli migliori per ogni funzione\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score, StratifiedKFold, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "import random as rd\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score, confusion_matrix, accuracy_score, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import dump, load\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kos = pd.read_csv('../Matrices/genome_ko_all.csv').set_index('Genome')\n",
    "functions = pd.read_csv('../Matrices/function_db.csv').set_index('genome_id')\n",
    "functions.insert(0, 'ID', functions['Unnamed: 0'])\n",
    "functions.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = kos.merge(functions,left_index=True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ko_input = data[kos.columns].drop('Species', axis = 1)\n",
    "function_input = data[functions.columns].drop(['scientific_name', 'ID'], axis = 1)\n",
    "y_col = [i for i in function_input.columns if function_input[i].sum() > 3]\n",
    "y_input = function_input[y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_models = pd.read_csv('../final_tool.csv').set_index('functional_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>functional_class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>photosynthetic_cyanobacteria</th>\n",
       "      <td>svm</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVC(C=1, cache_size=1000, kernel='linear', ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methanogenesis_by_CO2_reduction_with_H2</th>\n",
       "      <td>svm</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVC(C=1, cache_size=1000, kernel='linear', ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methanogenesis_by_reduction_of_methyl_compounds_with_H2</th>\n",
       "      <td>svm</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVC(C=1, cache_size=1000, kernel='linear', ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arsenite_oxidation_detoxification</th>\n",
       "      <td>svm</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SVC(C=1, cache_size=1000, kernel='linear', ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mammal_gut</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.971230</td>\n",
       "      <td>SVC(C=10, cache_size=1000, random_state=1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dissimilatory_arsenate_reduction</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.774056</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aerobic_anoxygenic_phototrophy</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.763690</td>\n",
       "      <td>LogisticRegression(C=1, max_iter=10000, random...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chitinolysis</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.748022</td>\n",
       "      <td>LogisticRegression(C=10, max_iter=10000, penal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dark_iron_oxidation</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.667620</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knallgas_bacteria</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.631683</td>\n",
       "      <td>LogisticRegression(C=0.01, max_iter=10000, ran...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   model     score  \\\n",
       "functional_class                                                     \n",
       "photosynthetic_cyanobacteria                         svm  1.000000   \n",
       "methanogenesis_by_CO2_reduction_with_H2              svm  1.000000   \n",
       "methanogenesis_by_reduction_of_methyl_compounds...   svm  1.000000   \n",
       "arsenite_oxidation_detoxification                    svm  1.000000   \n",
       "mammal_gut                                           svm  0.971230   \n",
       "...                                                  ...       ...   \n",
       "dissimilatory_arsenate_reduction                      lr  0.774056   \n",
       "aerobic_anoxygenic_phototrophy                        lr  0.763690   \n",
       "chitinolysis                                          lr  0.748022   \n",
       "dark_iron_oxidation                                   lr  0.667620   \n",
       "knallgas_bacteria                                     lr  0.631683   \n",
       "\n",
       "                                                                                           parameters  \n",
       "functional_class                                                                                       \n",
       "photosynthetic_cyanobacteria                        SVC(C=1, cache_size=1000, kernel='linear', ran...  \n",
       "methanogenesis_by_CO2_reduction_with_H2             SVC(C=1, cache_size=1000, kernel='linear', ran...  \n",
       "methanogenesis_by_reduction_of_methyl_compounds...  SVC(C=1, cache_size=1000, kernel='linear', ran...  \n",
       "arsenite_oxidation_detoxification                   SVC(C=1, cache_size=1000, kernel='linear', ran...  \n",
       "mammal_gut                                                 SVC(C=10, cache_size=1000, random_state=1)  \n",
       "...                                                                                               ...  \n",
       "dissimilatory_arsenate_reduction                    LogisticRegression(C=0.01, max_iter=10000, ran...  \n",
       "aerobic_anoxygenic_phototrophy                      LogisticRegression(C=1, max_iter=10000, random...  \n",
       "chitinolysis                                        LogisticRegression(C=10, max_iter=10000, penal...  \n",
       "dark_iron_oxidation                                 LogisticRegression(C=0.01, max_iter=10000, ran...  \n",
       "knallgas_bacteria                                   LogisticRegression(C=0.01, max_iter=10000, ran...  \n",
       "\n",
       "[89 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                                                svm\n",
       "score                                            0.97123\n",
       "parameters    SVC(C=10, cache_size=1000, random_state=1)\n",
       "Name: mammal_gut, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_models.loc['mammal_gut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['anammox', 'chloroplasts', 'nonphotosynthetic_cyanobacteria']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discarded_class = [i for i in function_input.columns if i not in y_input.columns]\n",
    "discarded_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier(function, x,y, chosen_pars):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, test_size = 0.2, random_state=1)\n",
    "    sc = StandardScaler()\n",
    "    x_train_normalized = sc.fit_transform(x_train)\n",
    "    print(x_train_normalized.shape)\n",
    "    best_model = eval(chosen_pars)\n",
    "    print(best_model)\n",
    "    best_model_fitted = best_model.fit(x_train_normalized, y_train)\n",
    "    # save the model\n",
    "    dump(best_model_fitted, open('model_'+function+'.sav', 'wb'))\n",
    "    # save the scaler\n",
    "    dump(sc, open('scaler_'+function+'.sav', 'wb'))\n",
    "    print(function + ': classifier saved!')\n",
    "    return  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acetoclastic_methanogenesis\n",
      "(11490, 11469)\n",
      "LogisticRegression(C=0.001, max_iter=10000, random_state=1, solver='liblinear')\n",
      "acetoclastic_methanogenesis: classifier saved!\n",
      "methanogenesis_by_disproportionation_of_methyl_groups\n",
      "(11490, 11469)\n",
      "RandomForestClassifier(n_jobs=4, random_state=1)\n",
      "methanogenesis_by_disproportionation_of_methyl_groups: classifier saved!\n",
      "methanogenesis_using_formate\n",
      "(11490, 11469)\n",
      "SVC(C=1, cache_size=1000, kernel='linear', random_state=1)\n",
      "methanogenesis_using_formate: classifier saved!\n",
      "methanogenesis_by_CO2_reduction_with_H2\n",
      "(11490, 11469)\n",
      "SVC(C=1, cache_size=1000, kernel='linear', random_state=1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [29], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chosen_models\u001b[38;5;241m.\u001b[39mloc[func][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(func)\n\u001b[0;32m----> 5\u001b[0m     classifier(func, ko_input, y_input[func], chosen_models\u001b[38;5;241m.\u001b[39mloc[func][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparameters\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn [23], line 8\u001b[0m, in \u001b[0;36mclassifier\u001b[0;34m(function, x, y, chosen_pars)\u001b[0m\n\u001b[1;32m      6\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(chosen_pars)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_model)\n\u001b[0;32m----> 8\u001b[0m best_model_fitted \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# save the model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m dump(best_model_fitted, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mfunction\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.sav\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/svm/_base.py:221\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;66;03m# var = E[X^2] - E[X]^2 if sparse\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m         X_var \u001b[38;5;241m=\u001b[39m (X\u001b[38;5;241m.\u001b[39mmultiply(X))\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m-\u001b[39m (X\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m X_var) \u001b[38;5;28;01mif\u001b[39;00m X_var \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/_methods.py:236\u001b[0m, in \u001b[0;36m_var\u001b[0;34m(a, axis, dtype, out, ddof, keepdims, where)\u001b[0m\n\u001b[1;32m    233\u001b[0m x \u001b[38;5;241m=\u001b[39m asanyarray(arr \u001b[38;5;241m-\u001b[39m arrmean)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, (nt\u001b[38;5;241m.\u001b[39mfloating, nt\u001b[38;5;241m.\u001b[39minteger)):\n\u001b[0;32m--> 236\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Fast-paths for built-in complex types\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01min\u001b[39;00m _complex_to_float:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train models with the best parameters and save them(and scalers); NN models are optimized elsewhere\n",
    "for func in list(y_input.columns):\n",
    "    if chosen_models.loc[func]['model'] !=\"nn\":\n",
    "        print(func)\n",
    "        classifier(func, ko_input, y_input[func], chosen_models.loc[func]['parameters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test on validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['anoxygenic_photoautotrophy_Fe_oxidizing', 'oil_bioremediation', 'dark_sulfite_oxidation', 'arsenate_respiration', 'manganese_respiration', 'dark_sulfur_oxidation', 'knallgas_bacteria', 'reductive_acetogenesis', 'dark_iron_oxidation', 'dark_thiosulfate_oxidation', 'chlorate_reducers', 'iron_respiration', 'anoxygenic_photoautotrophy_H2_oxidizing', 'nitrate_denitrification', 'chitinolysis', 'aerobic_anoxygenic_phototrophy', 'denitrification', 'dissimilatory_arsenate_reduction', 'dark_sulfide_oxidation', 'ureolysis', 'cellulolysis', 'thiosulfate_respiration', 'nitrous_oxide_denitrification', 'plastic_degradation', 'sulfur_respiration', 'aromatic_hydrocarbon_degradation', 'acetoclastic_methanogenesis', 'xylanolysis', 'sulfite_respiration', 'fumarate_respiration', 'dark_hydrogen_oxidation', 'nitrification', 'methanol_oxidation', 'sulfate_respiration', 'dark_oxidation_of_sulfur_compounds', 'nitrite_denitrification', 'arsenate_detoxification', 'anoxygenic_photoautotrophy_S_oxidizing', 'nitrate_respiration', 'nitrite_respiration', 'aromatic_compound_degradation', 'nitrate_ammonification', 'ligninolysis', 'nitrite_ammonification', 'phototrophy', 'respiration_of_sulfur_compounds', 'anoxygenic_photoautotrophy', 'methylotrophy', 'nitrogen_fixation', 'invertebrate_parasites', 'nitrogen_respiration', 'photoheterotrophy', 'chemoheterotrophy', 'nitrate_reduction', 'aerobic_ammonia_oxidation', 'predatory_or_exoparasitic', 'methanogenesis_using_formate', 'plant_pathogen', 'human_pathogens_meningitis', 'human_pathogens_gastroenteritis', 'hydrocarbon_degradation', 'manganese_oxidation', 'animal_parasites_or_symbionts', 'human_pathogens_all', 'photoautotrophy', 'human_pathogens_septicemia', 'aerobic_chemoheterotrophy', 'human_associated', 'aliphatic_non_methane_hydrocarbon_degradation', 'human_pathogens_pneumonia', 'fermentation', 'human_pathogens_diarrhea', 'mammal_gut', 'methanotrophy', 'human_gut', 'intracellular_parasites', 'methanogenesis_by_CO2_reduction_with_H2', 'methanogenesis_by_disproportionation_of_methyl_groups', 'methanogenesis_by_reduction_of_methyl_compounds_with_H2', 'hydrogenotrophic_methanogenesis', 'oxygenic_photoautotrophy', 'aerobic_nitrite_oxidation', 'methanogenesis', 'arsenite_oxidation_detoxification', 'arsenite_oxidation_energy_yielding', 'fish_parasites', 'dissimilatory_arsenite_oxidation', 'photosynthetic_cyanobacteria', 'human_pathogens_nosocomia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load validation data\n",
    "to_validate = pd.read_csv('./input_classifier/ko_df_validation.csv').set_index('Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_set(to_validate, training_set):\n",
    "    training_kos = training_set.columns\n",
    "    validation_kos = to_validate.columns\n",
    "    if len(set(training_kos).intersection(set(validation_kos))) == 0:\n",
    "        print('no common kos between provided ones and training')\n",
    "        return\n",
    "    else:\n",
    "        common = list(set(training_kos).intersection(set(validation_kos)))\n",
    "        print('{} common kos'.format(len(common)))\n",
    "        common_table = to_validate[common]\n",
    "        #remove orthologs in validation not in the training\n",
    "        to_remove = set(validation_kos) - set(training_kos)\n",
    "        print('{} kos present in user set but not in training set will be removed'.format(len(to_remove)))\n",
    "        missing = list(set(training_kos) - set(validation_kos))\n",
    "        print('{} kos missing from the users et will be add to train the classifiers'.format(len(missing)))\n",
    "        #missing_df = pd\n",
    "        missed = pd.DataFrame(0, index = to_validate.index, columns= missing)\n",
    "        to_submit = common_table.merge(missed, left_index = True, right_index = True)\n",
    "        #print(list(validation_kos))\n",
    "        to_submit = to_submit[list(training_kos)] #change order columns\n",
    "        print('Shape of training dataset: {}, Shape of user dataset: {}'.format(training_set.shape, to_submit.shape))\n",
    "        if list(to_submit.columns) != list(training_set.columns): \n",
    "            print('ERROR')\n",
    "            return\n",
    "    return to_submit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = get_validation_set(to_validate, ko_input)\n",
    "data_for_validation = validation.merge(functions,left_index=True, right_index = True)\n",
    "ko_validation = data_for_validation[validation.columns]\n",
    "function_validation = data_for_validation[classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human_pathogens_nosocomia\n",
      "photosynthetic_cyanobacteria\n",
      "dissimilatory_arsenite_oxidation\n",
      "fish_parasites\n",
      "arsenite_oxidation_energy_yielding\n",
      "arsenite_oxidation_detoxification\n"
     ]
    }
   ],
   "source": [
    "results_per_class = {}\n",
    "scores = {}\n",
    "for c in classes[::-1]:\n",
    "    print(c)\n",
    "    model = load(open('model_'+c+'.sav', 'rb'))\n",
    "    scaler = load(open('scaler_'+c+'.sav', 'rb'))\n",
    "    to_validate_norm = scaler.transform(ko_validation)\n",
    "    pred = model.predict(to_validate_norm)\n",
    "\n",
    "\n",
    "    results_per_class[c] = pred\n",
    "    scores[c] = [matthews_corrcoef(function_validation[c], pred), f1_score(function_validation[c], pred, zero_division=0), confusion_matrix(function_validation[c], pred), \n",
    "                 accuracy_score(function_validation[c], pred)]\n",
    "final_scores = pd.DataFrame(scores).T\n",
    "final_scores.to_csv(\"Validation_scores.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7088d53ce0fd003f797a719d3e4b4a5685c00ef08bccabffa76b86d48a32132f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
